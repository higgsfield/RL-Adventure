{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math, random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('../')\n",
    "from common.replay_buffer import PrioritizedReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Atari Environment</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common.wrappers import make_atari, wrap_deepmind, wrap_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env_id = \"DemonAttack-v0\"\n",
    "env    = make_atari(env_id)\n",
    "env    = wrap_deepmind(env)\n",
    "env    = wrap_pytorch(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Use Cuda</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Noisy Networks for Exploration</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>https://arxiv.org/abs/1706.10295</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, std_init=0.4):\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.in_features  = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init     = std_init\n",
    "        \n",
    "        self.weight_mu    = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        self.register_buffer('weight_epsilon', torch.FloatTensor(out_features, in_features))\n",
    "        \n",
    "        self.bias_mu    = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        self.register_buffer('bias_epsilon', torch.FloatTensor(out_features))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training: \n",
    "            weight = self.weight_mu + self.weight_sigma.mul(Variable(self.weight_epsilon))\n",
    "            bias   = self.bias_mu   + self.bias_sigma.mul(Variable(self.bias_epsilon))\n",
    "        else:\n",
    "            weight = self.weight_mu\n",
    "            bias   = self.bias_mu\n",
    "        \n",
    "        return F.linear(x, weight, bias)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        mu_range = 1 / math.sqrt(self.weight_mu.size(1))\n",
    "        \n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(self.std_init / math.sqrt(self.weight_sigma.size(1)))\n",
    "        \n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(self.std_init / math.sqrt(self.bias_sigma.size(0)))\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        epsilon_in  = self._scale_noise(self.in_features)\n",
    "        epsilon_out = self._scale_noise(self.out_features)\n",
    "        \n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(self._scale_noise(self.out_features))\n",
    "    \n",
    "    def _scale_noise(self, size):\n",
    "        x = torch.randn(size)\n",
    "        x = x.sign().mul(x.abs().sqrt())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Noisy DQN</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NoisyDQN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions):\n",
    "        super(NoisyDQN, self).__init__()\n",
    "        \n",
    "        self.linear =  nn.Linear(env.observation_space.shape[0], 128)\n",
    "        self.noisy1 = NoisyLinear(128, 128)\n",
    "        self.noisy2 = NoisyLinear(128, env.action_space.n)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear(x))\n",
    "        x = F.relu(self.noisy1(x))\n",
    "        x = self.noisy2(x)\n",
    "        return x\n",
    "    \n",
    "    def act(self, state):\n",
    "        state   = Variable(torch.FloatTensor(state).unsqueeze(0), volatile=True)\n",
    "        q_value = self.forward(state)\n",
    "        action  = q_value.max(1)[1].data[0]\n",
    "        return action\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        self.noisy1.reset_noise()\n",
    "        self.noisy2.reset_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_model = NoisyDQN(env.observation_space.shape[0], env.action_space.n)\n",
    "target_model  = NoisyDQN(env.observation_space.shape[0], env.action_space.n)\n",
    "\n",
    "if USE_CUDA:\n",
    "    current_model = current_model.cuda()\n",
    "    target_model  = target_model.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(current_model.parameters(), lr=0.0001)\n",
    "\n",
    "beta_start = 0.4\n",
    "beta_frames = 1000 \n",
    "beta_by_frame = lambda frame_idx: min(1.0, beta_start + frame_idx * (1.0 - beta_start) / beta_frames)\n",
    "\n",
    "replay_buffer = PrioritizedReplayBuffer(10000, alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Synchronize current policy net and target net</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_target(current_model, target_model):\n",
    "    target_model.load_state_dict(current_model.state_dict())\n",
    "    \n",
    "update_target(current_model, target_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Computing Temporal Difference Loss</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_td_loss(batch_size, beta):\n",
    "    state, action, reward, next_state, done, weights, indices = replay_buffer.sample(batch_size, beta) \n",
    "\n",
    "    state      = Variable(torch.FloatTensor(np.float32(state)))\n",
    "    next_state = Variable(torch.FloatTensor(np.float32(next_state)))\n",
    "    action     = Variable(torch.LongTensor(action))\n",
    "    reward     = Variable(torch.FloatTensor(reward))\n",
    "    done       = Variable(torch.FloatTensor(np.float32(done)))\n",
    "    weights    = Variable(torch.FloatTensor(weights))\n",
    "\n",
    "    q_values      = current_model(state)\n",
    "    next_q_values = target_model(next_state)\n",
    "\n",
    "    q_value          = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "    next_q_value     = next_q_values.max(1)[0]\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "    \n",
    "    loss  = (q_value - expected_q_value.detach()).pow(2) * weights\n",
    "    prios = loss + 1e-5\n",
    "    loss  = loss.mean()\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    replay_buffer.update_priorities(indices, prios.data.cpu().numpy())\n",
    "    current_model.reset_noise()\n",
    "    target_model.reset_noise()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><hr></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NoisyCnnDQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(NoisyCnnDQN, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.noisy1 = NoisyLinear(self.feature_size(), 512)\n",
    "        self.noisy2 = NoisyLinear(512, env.action_space.n)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        x = x / 255.\n",
    "        x = self.features(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "        \n",
    "        x = F.relu(self.noisy1(x))\n",
    "        x = self.noisy2(x)\n",
    "        return x\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        self.noisy1.reset_noise()\n",
    "        self.noisy2.reset_noise()\n",
    "        \n",
    "    def feature_size(self):\n",
    "        return self.features(autograd.Variable(torch.zeros(1, *self.input_shape))).view(1, -1).size(1)\n",
    "    \n",
    "    def act(self, state):\n",
    "        state   = Variable(torch.FloatTensor(np.float32(state)).unsqueeze(0), volatile=True)\n",
    "        q_value = self.forward(state)\n",
    "        action  = q_value.max(1)[1].data[0]\n",
    "        return action\n",
    "    \n",
    "    def predict(self, state):\n",
    "        state = Variable(torch.FloatTensor(np.float32(state)).unsqueeze(0), volatile=True)\n",
    "        q_value = self.forward(state)\n",
    "        return q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_model = NoisyCnnDQN(env.observation_space.shape, env.action_space.n)\n",
    "target_model  = NoisyCnnDQN(env.observation_space.shape, env.action_space.n)\n",
    "\n",
    "if USE_CUDA:\n",
    "    current_model = current_model.cuda()\n",
    "    target_model  = target_model.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(current_model.parameters(), lr=0.0001)\n",
    "\n",
    "beta_start = 0.4\n",
    "beta_frames = 100000\n",
    "beta_by_frame = lambda frame_idx: min(1.0, beta_start + frame_idx * (1.0 - beta_start) / beta_frames)\n",
    "\n",
    "replay_buffer = PrioritizedReplayBuffer(10000, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10342def0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([beta_by_frame(i) for i in range(1000000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-9e280f23588d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta_by_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_td_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_frames = 1000000\n",
    "batch_size = 32\n",
    "gamma      = 0.99\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "state = env.reset()\n",
    "for frame_idx in range(1, num_frames + 1):\n",
    "    action = current_model.act(state)\n",
    "    q_values = current_model.predict(state)\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    replay_buffer.push(state, action, reward, next_state, done)\n",
    "    \n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "    \n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "        \n",
    "    if len(replay_buffer) > batch_size:\n",
    "        beta = beta_by_frame(frame_idx)\n",
    "        loss = compute_td_loss(batch_size, beta)\n",
    "        losses.append(loss.data[0])\n",
    "        \n",
    "    if frame_idx % 10000 == 0:\n",
    "        plot(frame_idx, all_rewards, losses)\n",
    "        \n",
    "    if frame_idx % 1000 == 0:\n",
    "        update_target(current_model, target_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
