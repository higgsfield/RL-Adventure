{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math, random\n",
    "\n",
    "import gym\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F\n",
    "\n",
    "sys.path.append('../')\n",
    "from common.replay_buffer import PrioritizedReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Atari Environment</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common.wrappers import make_atari, wrap_deepmind, wrap_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env_id = \"ChopperCommand-v0\"\n",
    "env    = make_atari(env_id)\n",
    "env    = wrap_deepmind(env)\n",
    "env    = wrap_pytorch(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Use Cuda</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Noisy Networks for Exploration</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>https://arxiv.org/abs/1706.10295</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NoisyLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features, std_init=0.4):\n",
    "        super(NoisyLinear, self).__init__()\n",
    "        \n",
    "        self.in_features  = in_features\n",
    "        self.out_features = out_features\n",
    "        self.std_init     = std_init\n",
    "        \n",
    "        self.weight_mu    = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        self.weight_sigma = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        self.register_buffer('weight_epsilon', torch.FloatTensor(out_features, in_features))\n",
    "        \n",
    "        self.bias_mu    = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        self.bias_sigma = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        self.register_buffer('bias_epsilon', torch.FloatTensor(out_features))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "        self.reset_noise()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.training: \n",
    "            weight = self.weight_mu + self.weight_sigma.mul(Variable(self.weight_epsilon))\n",
    "            bias   = self.bias_mu   + self.bias_sigma.mul(Variable(self.bias_epsilon))\n",
    "        else:\n",
    "            weight = self.weight_mu\n",
    "            bias   = self.bias_mu\n",
    "        \n",
    "        return F.linear(x, weight, bias)\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        mu_range = 1 / math.sqrt(self.weight_mu.size(1))\n",
    "        \n",
    "        self.weight_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.weight_sigma.data.fill_(self.std_init / math.sqrt(self.weight_sigma.size(1)))\n",
    "        \n",
    "        self.bias_mu.data.uniform_(-mu_range, mu_range)\n",
    "        self.bias_sigma.data.fill_(self.std_init / math.sqrt(self.bias_sigma.size(0)))\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        epsilon_in  = self._scale_noise(self.in_features)\n",
    "        epsilon_out = self._scale_noise(self.out_features)\n",
    "        \n",
    "        self.weight_epsilon.copy_(epsilon_out.ger(epsilon_in))\n",
    "        self.bias_epsilon.copy_(self._scale_noise(self.out_features))\n",
    "    \n",
    "    def _scale_noise(self, size):\n",
    "        x = torch.randn(size)\n",
    "        x = x.sign().mul(x.abs().sqrt())\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Noisy DQN</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NoisyDQN(nn.Module):\n",
    "    def __init__(self, num_inputs, num_actions):\n",
    "        super(NoisyDQN, self).__init__()\n",
    "        \n",
    "        self.linear =  nn.Linear(env.observation_space.shape[0], 128)\n",
    "        self.noisy1 = NoisyLinear(128, 128)\n",
    "        self.noisy2 = NoisyLinear(128, env.action_space.n)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear(x))\n",
    "        x = F.relu(self.noisy1(x))\n",
    "        x = self.noisy2(x)\n",
    "        return x\n",
    "    \n",
    "    def act(self, state):\n",
    "        state   = Variable(torch.FloatTensor(state).unsqueeze(0), volatile=True)\n",
    "        q_value = self.forward(state)\n",
    "        action  = q_value.max(1)[1].data[0]\n",
    "        return action\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        self.noisy1.reset_noise()\n",
    "        self.noisy2.reset_noise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_model = NoisyDQN(env.observation_space.shape[0], env.action_space.n)\n",
    "target_model  = NoisyDQN(env.observation_space.shape[0], env.action_space.n)\n",
    "\n",
    "if USE_CUDA:\n",
    "    current_model = current_model.cuda()\n",
    "    target_model  = target_model.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(current_model.parameters(), lr=0.0001)\n",
    "\n",
    "beta_start = 0.4\n",
    "beta_frames = 1000 \n",
    "beta_by_frame = lambda frame_idx: min(1.0, beta_start + frame_idx * (1.0 - beta_start) / beta_frames)\n",
    "\n",
    "replay_buffer = PrioritizedReplayBuffer(10000, alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Synchronize current policy net and target net</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_target(current_model, target_model):\n",
    "    target_model.load_state_dict(current_model.state_dict())\n",
    "    \n",
    "update_target(current_model, target_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Computing Temporal Difference Loss</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_td_loss(batch_size, beta):\n",
    "    state, action, reward, next_state, done, weights, indices = replay_buffer.sample(batch_size, beta) \n",
    "\n",
    "    state      = Variable(torch.FloatTensor(np.float32(state)))\n",
    "    next_state = Variable(torch.FloatTensor(np.float32(next_state)))\n",
    "    action     = Variable(torch.LongTensor(action))\n",
    "    reward     = Variable(torch.FloatTensor(reward))\n",
    "    done       = Variable(torch.FloatTensor(np.float32(done)))\n",
    "    weights    = Variable(torch.FloatTensor(weights))\n",
    "\n",
    "    q_values      = current_model(state)\n",
    "    next_q_values = target_model(next_state)\n",
    "\n",
    "    q_value          = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "    next_q_value     = next_q_values.max(1)[0]\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "    \n",
    "    loss  = (q_value - expected_q_value.detach()).pow(2) * weights\n",
    "    prios = loss + 1e-5\n",
    "    loss  = loss.mean()\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    replay_buffer.update_priorities(indices, prios.data.cpu().numpy())\n",
    "    current_model.reset_noise()\n",
    "    target_model.reset_noise()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><hr></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NoisyCnnDQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(NoisyCnnDQN, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.noisy1 = NoisyLinear(self.feature_size(), 512)\n",
    "        self.noisy2 = NoisyLinear(512, env.action_space.n)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        x = x / 255.\n",
    "        x = self.features(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "        \n",
    "        x = F.relu(self.noisy1(x))\n",
    "        x = self.noisy2(x)\n",
    "        return x\n",
    "    \n",
    "    def reset_noise(self):\n",
    "        self.noisy1.reset_noise()\n",
    "        self.noisy2.reset_noise()\n",
    "        \n",
    "    def feature_size(self):\n",
    "        return self.features(autograd.Variable(torch.zeros(1, *self.input_shape))).view(1, -1).size(1)\n",
    "    \n",
    "    def act(self, state):\n",
    "        state   = Variable(torch.FloatTensor(np.float32(state)).unsqueeze(0), volatile=True)\n",
    "        q_value = self.forward(state)\n",
    "        action  = q_value.max(1)[1].data[0]\n",
    "        return action\n",
    "    \n",
    "    def predict(self, state):\n",
    "        state = Variable(torch.FloatTensor(np.float32(state)).unsqueeze(0), volatile=True)\n",
    "        q_value = self.forward(state)\n",
    "        return q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_model = NoisyCnnDQN(env.observation_space.shape, env.action_space.n)\n",
    "target_model  = NoisyCnnDQN(env.observation_space.shape, env.action_space.n)\n",
    "\n",
    "if USE_CUDA:\n",
    "    current_model = current_model.cuda()\n",
    "    target_model  = target_model.cuda()\n",
    "    \n",
    "optimizer = optim.Adam(current_model.parameters(), lr=0.0001)\n",
    "\n",
    "beta_start = 0.4\n",
    "beta_frames = 100000\n",
    "beta_by_frame = lambda frame_idx: min(1.0, beta_start + frame_idx * (1.0 - beta_start) / beta_frames)\n",
    "\n",
    "replay_buffer = PrioritizedReplayBuffer(10000, alpha=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f19d014f710>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1a5da49e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([beta_by_frame(i) for i in range(1000000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    p1 = np.exp(p) / np.sum(np.exp(p))\n",
    "    return -sum(p1*np.log(p1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_idx:     176, (0.00 %)"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-1b51db498180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplay_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta_by_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_td_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-8c357bc20d36>\u001b[0m in \u001b[0;36mcompute_td_loss\u001b[0;34m(batch_size, beta)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mreplay_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_priorities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprios\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mcurrent_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-1e0f7c24fe5a>\u001b[0m in \u001b[0;36mreset_noise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoisy1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoisy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-7b0af4def0d1>\u001b[0m in \u001b[0;36mreset_noise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mepsilon_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_epsilon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_epsilon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_frames = 3000000\n",
    "batch_size = 32\n",
    "gamma      = 0.99\n",
    "episode = 0\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "state_traj = []\n",
    "q_value_traj = []\n",
    "q_entropy_traj = []\n",
    "\n",
    "episode_state = []\n",
    "episode_q_val = []\n",
    "episode_q_entropy = []\n",
    "\n",
    "state = env.reset()\n",
    "for frame_idx in range(1, num_frames + 1):\n",
    "    action = current_model.act(state)\n",
    "    \n",
    "    if episode % 20 == 0:\n",
    "        q_values = current_model.predict(state).data.cpu().numpy()[0]\n",
    "        episode_state.append(state)\n",
    "        episode_q_val.append(q_values)\n",
    "        #q_entropy = entropy(q_values)\n",
    "        #episode_q_entropy.append(q_entropy)\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    replay_buffer.push(state, action, reward, next_state, done)\n",
    "    \n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "    \n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "        if episode % 20 == 0:\n",
    "            state_traj.append(episode_state)\n",
    "            q_value_traj.append(episode_q_val)\n",
    "            #q_entropy_traj.append(episode_q_entropy)\n",
    "        \n",
    "        episode += 1\n",
    "        episode_state = []\n",
    "        episode_q_val = []\n",
    "        episode_q_entropy = []\n",
    "        \n",
    "    if len(replay_buffer) > batch_size:\n",
    "        beta = beta_by_frame(frame_idx)\n",
    "        loss = compute_td_loss(batch_size, beta)\n",
    "        losses.append(loss.data[0])\n",
    "        \n",
    "    if frame_idx % 10000 == 0:\n",
    "        plot(frame_idx, all_rewards, losses)\n",
    "        \n",
    "    if frame_idx % 1000 == 0:\n",
    "        update_target(current_model, target_model)\n",
    "    \n",
    "    print('\\rframe_idx: %7d, (%.2f %%)' %(frame_idx, frame_idx/num_frames), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/minzy/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type NoisyCnnDQN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/Users/minzy/anaconda3/envs/pytorch/lib/python3.5/site-packages/torch/serialization.py:159: UserWarning: Couldn't retrieve source code for container of type NoisyLinear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "from common.save_file import *\n",
    "\n",
    "model_dir = \"model\"\n",
    "var_dir = \"var\"\n",
    "name = \"nosiy_\" + env_id\n",
    "\n",
    "save_model(current_model, model_dir, name)\n",
    "\n",
    "var_dict = {\n",
    "            \"all_rewards\": all_rewards,\n",
    "            \"losses\": losses,\n",
    "            \"state_traj\": state_traj,\n",
    "            \"q_value_traj\": q_value_traj\n",
    "            #\"q_entropy\": q_entropy_traj\n",
    "           }\n",
    "\n",
    "save_variable(name, var_dir, var_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
