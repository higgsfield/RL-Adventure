{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "- initialize : random  \n",
    "- epsilon : 1 to 0.1until 150000 with exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math, random\n",
    "import os, sys, time\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.append('../')\n",
    "from common.wrappers import make_atari, wrap_deepmind, wrap_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Set configuration </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from common.config import *\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "env_id = \"Boxing-v0\"\n",
    "env    = make_atari(env_id)\n",
    "env    = wrap_deepmind(env)\n",
    "env    = wrap_pytorch(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Use Cuda</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Replay Buffer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, next_q_value, next_e_value, done):\n",
    "        state      = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "            \n",
    "        self.buffer.append((state, action, reward, next_state, next_q_value, next_e_value, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, next_q_value, next_e_value, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), next_q_value, next_e_value, done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Computing Temporal Difference Loss</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_td_loss(batch_size):\n",
    "    state, action, reward, next_state, next_q_value, next_e_value, done = replay_buffer.sample(batch_size)\n",
    "       \n",
    "    state      = Variable(torch.FloatTensor(np.float32(state)))\n",
    "    next_state = Variable(torch.FloatTensor(np.float32(next_state)), volatile=True)\n",
    "    action     = Variable(torch.LongTensor(action))\n",
    "    reward     = Variable(torch.FloatTensor(reward))\n",
    "    done       = Variable(torch.FloatTensor(done))\n",
    "    \n",
    "\n",
    "    q_values      = q_model(state)\n",
    "    next_q_values = q_model(next_state)\n",
    "    \n",
    "    e_values      = e_model(state)\n",
    "    next_e_values = e_model(next_state)\n",
    "\n",
    "    q_value          = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "    #next_q_value     = next_q_values.max(1)[0]\n",
    "    next_q_value = Variable(torch.FloatTensor(np.array(next_q_value)))\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "    \n",
    "    e_value          = e_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "    #next_e_value     = next_e_values.max(1)[0]\n",
    "    next_e_value = Variable(torch.FloatTensor(np.array(next_e_value)))\n",
    "    expected_e_value = gamma * next_e_value * (1 - done)\n",
    "    \n",
    "    q_loss = (q_value - Variable(expected_q_value.data)).pow(2).mean()\n",
    "    e_loss = (e_value - Variable(expected_e_value.data)).pow(2).mean()\n",
    "\n",
    "\n",
    "        \n",
    "    q_optimizer.zero_grad()\n",
    "    q_loss.backward()\n",
    "    q_optimizer.step()\n",
    "    \n",
    "    e_optimizer.zero_grad()\n",
    "    e_loss.backward()\n",
    "    e_optimizer.step()\n",
    "    \n",
    "    return q_loss, e_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><hr></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Atari Environment</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CnnDQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions, is_Evalue):\n",
    "        super(CnnDQN, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.num_actions = num_actions\n",
    "        self.is_Evalue = is_Evalue\n",
    "        \n",
    "        if is_Evalue:\n",
    "            self.shift = 10\n",
    "        else:\n",
    "            self.shift = 0\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.feature_size(), 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.num_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        if self.is_Evalue:\n",
    "            x = F.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "    def feature_size(self):\n",
    "        return self.features(autograd.Variable(torch.zeros(1, *self.input_shape))).view(1, -1).size(1)\n",
    "    \n",
    "    def act(self, state, epsilon):\n",
    "        if random.random() > epsilon:\n",
    "            state   = Variable(torch.FloatTensor(np.float32(state)).unsqueeze(0), volatile=True)\n",
    "            q_value = self.forward(state)\n",
    "            action  = q_value.max(1)[1].data[0]\n",
    "        else:\n",
    "            action = random.randrange(env.action_space.n)\n",
    "        return action\n",
    "    \n",
    "    def predict(self, state):\n",
    "        state = Variable(torch.FloatTensor(np.float32(state)).unsqueeze(0), volatile=True)\n",
    "        q_value = self.forward(state)\n",
    "        return q_value\n",
    "    \n",
    "    def weights_init(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1 and classname.find('Layer') == -1:\n",
    "            nn.init.xavier_normal(m.weight)\n",
    "        elif classname.find('Linear') != -1:\n",
    "            #nn.init.constant(m.weight,0)\n",
    "            nn.init.xavier_normal(m.weight)\n",
    "            nn.init.constant(m.bias, 0.1)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            m.weight.data.normal_(1.0, 0.02)\n",
    "            m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:58: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:61: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:62: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    }
   ],
   "source": [
    "q_model = CnnDQN(env.observation_space.shape, env.action_space.n, False)\n",
    "e_model = CnnDQN(env.observation_space.shape, env.action_space.n, True)\n",
    "\n",
    "q_model.apply(q_model.weights_init)\n",
    "e_model.apply(e_model.weights_init)\n",
    "\n",
    "if USE_CUDA:\n",
    "    q_model = q_model.cuda()\n",
    "    e_model = e_model.cuda()\n",
    "    \n",
    "q_optimizer = optim.Adam(q_model.parameters(), lr=cfg.LEARNING_RATE)\n",
    "e_optimizer = optim.Adam(e_model.parameters(), lr=cfg.LEARNING_RATE)\n",
    "\n",
    "replay_initial = cfg.REPLAY_INIT\n",
    "replay_buffer = ReplayBuffer(cfg.REPLAY_BUFFER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:1: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.init.constant(e_model.fc[2].weight.data,0)\n",
    "nn.init.constant(e_model.fc[2].bias.data,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epsilon Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2f55bfdd30>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2f68f3b7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epsilon_start = cfg.EPSILON_START\n",
    "epsilon_final = cfg.EPSILON_FINAL\n",
    "epsilon_decay = cfg.EPSILON_DECAY\n",
    "\n",
    "epsilon_by_frame = lambda frame_idx: epsilon_final + (epsilon_start - epsilon_final) * math.exp(-1. * frame_idx / epsilon_decay)\n",
    "plt.plot([epsilon_by_frame(i) for i in range(1000000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    p1 = np.exp(p) / np.sum(np.exp(p))\n",
    "    return -sum(p1*np.log(p1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_idx:    2711, (0.09 %)"
     ]
    }
   ],
   "source": [
    "num_frames = cfg.NUM_FRAMES\n",
    "batch_size = cfg.BATCH_SIZE\n",
    "gamma      = cfg.GAMMA\n",
    "episode = 0\n",
    "\n",
    "q_losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "state_traj = []\n",
    "q_value_traj = []\n",
    "\n",
    "episode_state = []\n",
    "episode_q_val = []\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "state = env.reset()\n",
    "for frame_idx in range(1, num_frames + 1):\n",
    "    epsilon = epsilon_by_frame(frame_idx)\n",
    "    action = q_model.act(state, epsilon)\n",
    "    \n",
    "    q_values = q_model.predict(state)\n",
    "    e_value = e_model.predict(state).data.cpu().numpy()[0][action]\n",
    "    e_bonus = 0.05/(np.sqrt(-np.log(e_value+1e-8))+1e-8)\n",
    "    \n",
    "    if episode % 20 == 0:\n",
    "        q_values = q_model.predict(state).data.cpu().numpy()[0]\n",
    "        episode_state.append(state)\n",
    "        episode_q_val.append(q_values)\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    reward += e_bonus\n",
    "    \n",
    "    next_action = q_model.act(next_state, 0)\n",
    "    next_q_value = q_model.predict(next_state).data.cpu().numpy()[0][next_action]\n",
    "    next_e_value = e_model.predict(next_state).data.cpu().numpy()[0][next_action]\n",
    "\n",
    "\n",
    "    replay_buffer.push(state, action, reward, next_state, next_q_value, next_e_value, done)\n",
    "    \n",
    "    state = next_state\n",
    "    episode_reward += (reward - e_bonus)\n",
    "    \n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "        if episode % 20 == 0:\n",
    "            state_traj.append(episode_state)\n",
    "            q_value_traj.append(episode_q_val)\n",
    "            \n",
    "        episode += 1\n",
    "        episode_state = []\n",
    "        episode_q_val = []\n",
    "        episode_q_entropy = []\n",
    "        \n",
    "    if len(replay_buffer) > replay_initial:\n",
    "        q_loss, _ = compute_td_loss(batch_size)\n",
    "        q_losses.append(q_loss.data[0])\n",
    "\n",
    "        \n",
    "    if frame_idx % 10000 == 0:\n",
    "        plot(frame_idx, all_rewards, q_losses)\n",
    "        print('\\rtraning_speed: %.2f 1e4_frames/s' %(time.time()-start_time))\n",
    "        start_time = time.time()\n",
    "        \n",
    "    print('\\rframe_idx: %7d, (%.2f %%)' %(frame_idx, frame_idx/num_frames*100), end='')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from common.save_file import *\n",
    "\n",
    "model_dir = cfg.MODEL_DIR\n",
    "var_dir = cfg.VAR_DIR\n",
    "name = \"epsilon_\" + env_id\n",
    "\n",
    "save_model(q_model, model_dir, name)\n",
    "\n",
    "var_dict = {\n",
    "            \"all_rewards\": all_rewards,\n",
    "            \"losses\": q_losses,\n",
    "            \"state_traj\": state_traj,\n",
    "            \"q_value_traj\": q_value_traj\n",
    "           }\n",
    "\n",
    "save_variable(name, var_dir, var_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
