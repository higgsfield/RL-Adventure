{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:22:42.342552Z",
     "start_time": "2018-06-19T12:22:41.881933Z"
    }
   },
   "outputs": [],
   "source": [
    "import math, random\n",
    "import gym\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd \n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:22:42.674399Z",
     "start_time": "2018-06-19T12:22:42.361783Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:22:42.927145Z",
     "start_time": "2018-06-19T12:22:42.803130Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('../')\n",
    "from common.wrappers import make_atari, wrap_deepmind, wrap_pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Set configuration </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:22:43.835849Z",
     "start_time": "2018-06-19T12:22:43.826901Z"
    }
   },
   "outputs": [],
   "source": [
    "from common.config import *\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Atari Environment</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:28:29.587007Z",
     "start_time": "2018-06-19T12:28:29.343946Z"
    }
   },
   "outputs": [],
   "source": [
    "env_id = \"DemonAttack-v0\"\n",
    "env    = make_atari(env_id)\n",
    "env    = wrap_deepmind(env)\n",
    "env    = wrap_pytorch(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Use Cuda</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:21:34.753349Z",
     "start_time": "2018-06-19T12:21:34.750303Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:21:38.341932Z",
     "start_time": "2018-06-19T12:21:38.336350Z"
    }
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "Variable = lambda *args, **kwargs: autograd.Variable(*args, **kwargs).cuda() if USE_CUDA else autograd.Variable(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Replay Buffer</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:21:42.024901Z",
     "start_time": "2018-06-19T12:21:42.006905Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        state      = np.expand_dims(state, 0)\n",
    "        next_state = np.expand_dims(next_state, 0)\n",
    "            \n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        state, action, reward, next_state, done = zip(*random.sample(self.buffer, batch_size))\n",
    "        return np.concatenate(state), action, reward, np.concatenate(next_state), done\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:21:45.573994Z",
     "start_time": "2018-06-19T12:21:45.566737Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot(frame_idx, rewards, losses):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title('frame %s. reward: %s' % (frame_idx, np.mean(rewards[-10:])))\n",
    "    plt.plot(rewards)\n",
    "    plt.subplot(132)\n",
    "    plt.title('loss')\n",
    "    plt.plot(losses)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Deep Q Network </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:21:49.268326Z",
     "start_time": "2018-06-19T12:21:49.145762Z"
    }
   },
   "outputs": [],
   "source": [
    "class CnnDQN(nn.Module):\n",
    "    def __init__(self, input_shape, num_actions):\n",
    "        super(CnnDQN, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.feature_size(), 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.num_actions)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x /= 255.0\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "    def feature_size(self):\n",
    "        return self.features(autograd.Variable(torch.zeros(1, *self.input_shape))).view(1, -1).size(1)\n",
    "    \n",
    "    def act(self, state, epsilon):\n",
    "        if random.random() > epsilon:\n",
    "            state   = Variable(torch.FloatTensor(np.float32(state)).unsqueeze(0), volatile=True)\n",
    "            q_value = self.forward(state)\n",
    "            action  = q_value.max(1)[1].data[0]\n",
    "        else:\n",
    "            action = random.randrange(env.action_space.n)\n",
    "        return action\n",
    "    \n",
    "    def predict(self, state):\n",
    "        state = Variable(torch.FloatTensor(np.float32(state)).unsqueeze(0), volatile=True)\n",
    "        q_value = self.forward(state)\n",
    "        return q_value\n",
    "    \n",
    "    def weights_init(self, m):\n",
    "        classname = m.__class__.__name__\n",
    "        if classname.find('Conv') != -1 and classname.find('Layer') == -1:\n",
    "            nn.init.xavier_normal(m.weight)\n",
    "        elif classname.find('Linear') != -1:\n",
    "            nn.init.xavier_normal(m.weight)\n",
    "            nn.init.constant(m.bias, 0.1)\n",
    "        elif classname.find('BatchNorm') != -1:\n",
    "            m.weight.data.normal_(1.0, 0.02)\n",
    "            m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:21:53.029395Z",
     "start_time": "2018-06-19T12:21:52.865895Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:50: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:52: UserWarning: nn.init.xavier_normal is now deprecated in favor of nn.init.xavier_normal_.\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:53: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    }
   ],
   "source": [
    "current_model = CnnDQN(env.observation_space.shape, env.action_space.n)\n",
    "target_model = CnnDQN(env.observation_space.shape, env.action_space.n)\n",
    "\n",
    "current_model.apply(current_model.weights_init)\n",
    "\n",
    "if USE_CUDA:\n",
    "    current_model = current_model.cuda()\n",
    "    target_model = target_model.cuda()\n",
    "    \n",
    "optimizer = optim.RMSprop(current_model.parameters(), lr=cfg.LEARNING_RATE)\n",
    "\n",
    "replay_initial = cfg.REPLAY_INIT\n",
    "replay_buffer = ReplayBuffer(cfg.REPLAY_BUFFER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronize current net and target net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:21:56.530906Z",
     "start_time": "2018-06-19T12:21:56.527730Z"
    }
   },
   "outputs": [],
   "source": [
    "def update_target(current_model, target_model):\n",
    "    target_model.load_state_dict(current_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:22:00.032289Z",
     "start_time": "2018-06-19T12:22:00.029239Z"
    }
   },
   "outputs": [],
   "source": [
    "update_target(current_model, target_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Computing Temporal Difference Loss</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:22:03.597044Z",
     "start_time": "2018-06-19T12:22:03.566573Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_td_loss(batch_size):\n",
    "    state, action, reward, next_state, done = replay_buffer.sample(batch_size)\n",
    "\n",
    "    state      = Variable(torch.FloatTensor(np.float32(state)))\n",
    "    next_state = Variable(torch.FloatTensor(np.float32(next_state)), volatile=True)\n",
    "    action     = Variable(torch.LongTensor(action))\n",
    "    reward     = Variable(torch.FloatTensor(reward))\n",
    "    done       = Variable(torch.FloatTensor(done))\n",
    "\n",
    "    q_values      = current_model(state)\n",
    "    next_q_values = target_model(next_state)\n",
    "\n",
    "    q_value          = q_values.gather(1, action.unsqueeze(1)).squeeze(1)\n",
    "    next_q_value     = next_q_values.max(1)[0]\n",
    "    expected_q_value = reward + gamma * next_q_value * (1 - done)\n",
    "    \n",
    "    loss = (q_value - Variable(expected_q_value.data)).pow(2).mean()\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Epsilon greedy exploration</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:22:07.668868Z",
     "start_time": "2018-06-19T12:22:07.387446Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f867c0f5978>]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f869c133ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epsilon_start = cfg.EPSILON_START\n",
    "epsilon_final = cfg.EPSILON_FINAL\n",
    "epsilon_decay = cfg.EPSILON_DECAY\n",
    "\n",
    "epsilon_by_frame = lambda frame_idx: max(epsilon_start - (epsilon_start - epsilon_final) * (frame_idx / epsilon_decay), epsilon_final)\n",
    "plt.plot([epsilon_by_frame(i) for i in range(100000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:22:11.361538Z",
     "start_time": "2018-06-19T12:22:11.356124Z"
    }
   },
   "outputs": [],
   "source": [
    "def entropy(p):\n",
    "    p1 = np.exp(p) / np.sum(np.exp(p))\n",
    "    return -sum(p1*np.log(p1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Training </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:22:27.488406Z",
     "start_time": "2018-06-19T12:22:15.143619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "frame_idx:       1, (0.00 %)\r",
      "frame_idx:       2, (0.00 %)\r",
      "frame_idx:       3, (0.00 %)\r",
      "frame_idx:       4, (0.00 %)\r",
      "frame_idx:       5, (0.00 %)\r",
      "frame_idx:       6, (0.00 %)\r",
      "frame_idx:       7, (0.00 %)\r",
      "frame_idx:       8, (0.00 %)\r",
      "frame_idx:       9, (0.00 %)\r",
      "frame_idx:      10, (0.00 %)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:2: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame_idx:    3880, (0.08 %)"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-8016c3f551cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mall_rewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisode_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mepisode_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ideaHome/Dropbox/SJ/ML/DLC/team/RL-Adventure/common/wrappers.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mRewardWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gym/core.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ideaHome/Dropbox/SJ/ML/DLC/team/RL-Adventure/common/wrappers.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ideaHome/Dropbox/SJ/ML/DLC/team/RL-Adventure/common/wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwas_real_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# check current lives, make loss of life terminal,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ideaHome/Dropbox/SJ/ML/DLC/team/RL-Adventure/common/wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m             \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obs_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_skip\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obs_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ideaHome/Dropbox/SJ/ML/DLC/team/RL-Adventure/common/wrappers.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, ac)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFireResetEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_episode_started_at\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframeskip\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/atari_py/ale_python_interface.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0male_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_frames = cfg.NUM_FRAMES\n",
    "batch_size = cfg.BATCH_SIZE\n",
    "gamma      = cfg.GAMMA\n",
    "episode = 0\n",
    "\n",
    "losses = []\n",
    "all_rewards = []\n",
    "episode_reward = 0\n",
    "\n",
    "state_traj = []\n",
    "q_value_traj = []\n",
    "\n",
    "episode_state = []\n",
    "episode_q_val = []\n",
    "\n",
    "state = env.reset()\n",
    "for frame_idx in range(1, num_frames + 1):\n",
    "    epsilon = epsilon_by_frame(frame_idx)\n",
    "    action = current_model.act(state, epsilon)\n",
    "\n",
    "    if episode % 20 == 0:\n",
    "        q_values = current_model.predict(state).data.cpu().numpy()[0]\n",
    "        episode_state.append(state)\n",
    "        episode_q_val.append(q_values)\n",
    "    \n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    replay_buffer.push(state, action, reward, next_state, done)\n",
    "    \n",
    "    state = next_state\n",
    "    episode_reward += reward\n",
    "    \n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        all_rewards.append(episode_reward)\n",
    "        episode_reward = 0\n",
    "        if episode % 20 == 0:\n",
    "            state_traj.append(episode_state)\n",
    "            q_value_traj.append(episode_q_val)\n",
    "        \n",
    "        episode += 1\n",
    "        episode_state = []\n",
    "        episode_q_val = []\n",
    "        \n",
    "    if len(replay_buffer) > replay_initial:\n",
    "        loss = compute_td_loss(batch_size)\n",
    "        losses.append(loss.data[0])\n",
    "        \n",
    "    if frame_idx % 10000 == 0:\n",
    "        plot(frame_idx, all_rewards, losses)\n",
    "        update_target(current_model, target_model)\n",
    "    \n",
    "    print('\\rframe_idx: %7d, (%.2f %%)' %(frame_idx, frame_idx/num_frames*100), end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:22:27.492279Z",
     "start_time": "2018-06-19T12:21:39.026Z"
    }
   },
   "outputs": [],
   "source": [
    "from common.save_file import *\n",
    "\n",
    "model_dir = cfg.MODEL_DIR\n",
    "var_dir = cfg.VAR_DIR\n",
    "name = \"epsilon_\" + env_id\n",
    "\n",
    "save_model(current_model, model_dir, name)\n",
    "\n",
    "var_dict = {\n",
    "            \"all_rewards\": all_rewards,\n",
    "            \"losses\": losses,\n",
    "            \"state_traj\": state_traj,\n",
    "            \"q_value_traj\": q_value_traj\n",
    "           }\n",
    "\n",
    "save_variable(name, var_dir, var_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-19T12:22:27.498314Z",
     "start_time": "2018-06-19T12:21:39.639Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load('model/epsilon_DemonAttack-v0.model')\n",
    "state = env.reset()\n",
    "done = False\n",
    "for i in range(10):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = model.act(state,0.1)\n",
    "        #action = env.action_space.sample()\n",
    "        state, reward, done, info = env.step(action)\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
